Note that the same feature can be used for different events . Feature Description Position difference in position , distance to border , overlap with border ; Intensity difference in intensity histogram / sum / mean / deviation , intensity of father cell ; Shape difference in shape , difference in size , shape compactness , shape evenness ; Others division angle pattern , mass evenness , eccentricity of father cell . We evaluated the proposed method on two publicly available image sequences provided in conjunction with the DCellIQ project _CITE_ [ 16 ] and the Mitocheck project [ 12 ]. The two datasets show a certain degree of variations such as illumination , cell density and image compression artifacts ( Fig . 2 ).__label__Method|Algorithm|Extent
Using these words can express the richest meaning with the less characters . Chinese micro - blog texts are unrestrained . In this task we followed the tagging schema of “ Specification for Corpus Processing at Peking University ” _CITE_ in the design of our model . In this word , under the assumption that a segmentation system for general text is already good , for a special domain we only need to do some modification to make the segmentation result better . The main frame of this system is using ICTCLAS as the segmentation tool .__label__Method|Algorithm|Extent
Since the entire correlation graph is too large , we build a 3 - layer hierarchy by clustering the learned topics , with their learned correlation strength as the similarity measure . Fig . 4 shows a part of the hierarchy _CITE_ , where the subgraph A represents the top layer with 10 clusters . The subgraphs B and C are two second layer clusters ; and D and E are two correlation subgraphs consisting of leaf nodes ( i . e ., learned topics ). To represent their semantic meanings , we present 4 most frequent words for each topic ; and for each topic cluster , we also show most frequent words by building a hyper - topic that aggregates all the included topics .__label__Method|Algorithm|Introduce
Moreover , pKBR and kRegBayes run faster than KBR . The total running times for 50 random datasets of pKBR , kRegBayes and KBR are respectively 601 . 3s , 677 . 5s and 3667 . 4s . Camera position recovery In this experiment , we build a scene containing a table and a chair , which is derived from classchair . pov ( _CITE_ ). With a fixed focal point , the position of the camera uniquely determines the view of the scene . The task of this experiment is to estimate the position of the camera given the image .__label__Supplement|Website|Extent
Figure 2 gives an overview of the general architecture . The eHumanities Desktop is implemented as a client / server system which can be used via any JavaScript / Java capable Web Browser . The GUI is based on the ExtJS Framework _CITE_ and provides a look and feel similar to Windows Vista . The server side is based on Java Servlet technology using the Tomcat Servlet Container . The core of the system is the Command Dispatcher which manages the communication with the client and the execution of tasks like downloading a document for example .__label__Method|Code|Extent
However , on tasks like machine translation with a very large number of input features , a Laplacian L1 regularization that also attempts to maximize the number of zero weights is highly desirable . A new L1 - regularized Maxent algorithms was proposed for density estimation ( Dudik et al ., 2004 ) and we adapted it to classification . We found this algorithm to converge faster than the current state - ofthe - art in Maxent training , which is L2 - regularized L - BFGS ( Malouf , 2002 ) _CITE_ . Moreover , the number of trained parameters is considerably smaller . We have performed experiments on the IWSLT06 Chinese - English training and development sets from 2005 and 2006 .__label__Method|Algorithm|Compare
This work is licensed under a Creative Commons Attribution 4 . 0 International Licence . Page numbers and proceedings footer are added by the organisers . Licence details : _CITE___label__Supplement|License|Other
All models are implemented in Theano [ 16 ], based on the implementation of restricted - capacity uRNNs by [ 10 ], available from _CITE_ All code to replicate our results is available from https :// github . com / stwisdom / urnn . All models use RMSprop [ 15 ] for optimization , except that full - capacity uRNNs optimize their recurrence matrices with a fixed learning rate using the update step ( 6 ) and optional RMSprop - style gradient normalization .__label__Method|Code|Extent
The first step involves extraction of semantic and temporal features for the annotated medical concepts , as described in Section 4 from both corpora . The semantic relatedness scores are computed using the kDLS ( Xiang et al ., 2011 ) method to calculate the relationship between concepts in the UMLS with value of - y set to 7 . The type of relation between medical concepts is derived by matching word stems in each medical concept using the Lucene _CITE_ implementation of the Porter stemming algorithm . We query the latest release ( UMLS 2011AB ) of the UMLS Metathesaurus for finding a match between medical concept and the UMLS definition or UMLS atoms . The WordNet similarity score is computed using Java API for WordNet Searching ( JAWS ). 10 Explicit temporal expressions annotated in the corpora are included in our temporal feature set .__label__Method|Code|Use
We have also performed experiments with different values of a and 6 . Despite the fact that larger a and 6 increase label independence on the graph structure and undermine the effectiveness of both V / E - optimality heuristics , we have seen that whenever the V - optimality establishes a superiority over random selections , E - optimality yields better performance . The active learning heuristics to be compared are : _CITE_ number of papers bearing both scholars ’ names . The largest connected component has 1711 nodes and 2898 edges . The node labels were hand assigned in Ji & Han ( 2012 ) to one of the four expertise areas of the scholars : machine learning , data mining , information retrieval , and databases .__label__Method|Algorithm|Compare
Thus we will focus on making comparison to the PGBN with a single layer , with its layer width set to be large to approximate the performance of the gamma - negative binomial process PFA . We evaluate the PGBNs ’ performance by examining both how well they unsupervisedly extract low - dimensional features for document classification , and how well they predict heldout word tokens . Matlab code will be available in _CITE_ We use Algorithm 1 to learn , in a layer - wise manner , from the training data the weight matrices ( D ( 1 ),...,( D ( Tmax ) and the top - layer hidden units ’ gamma shape parameters r : to add layer T to a previously trained network with T − 1 layers , we use BT iterations to jointly train ( D ( T ) and r together with {( D ( t )} 1 , T − 1 , prune the inactive factors of layer T , and continue the joint training with another CT iterations . We set the hyper - parameters as a0 = b0 = 0 . 01 and e0 = f0 = 1 .__label__Method|Code|Produce
In this Section , we provide experimental results for our framework on data from remote sensing , and on a set of large text classification tasks with very many classes , the latter are hierarchical . We use the satimage remote sensing task from the statlog repository . _CITE_ This task has been used in the extensive SVM multi - class study of [ 5 ], where it is among the datasets on which the different methods show the most variance . It has n = 4435 training , m = 2000 test cases , and C = 6 classes . We use the isotropic Gaussian ( RBF ) kernel We compare the methods mc - sep ( ours with separate kernels for each class ; 12 hyperparameters ), mc - tied ( ours with a single shared kernel ; 2 hyperparameters ), ] rest ( one - against - rest : C binary classifiers are trained separately to discriminate c from the rest , they are voted by log probability upon prediction ; 12 hyperparameters ).__label__Material|Data|Extent
We thank the Gatsby Charitable Foundation for generous funding . We thank Ryan Adams and Iain Murray for code and comments ; and Jakob Macke and Lars Buesing for useful discussions . The grasshopper data was collected by Ariel Rokem at Andreas Herz ’ s lab and provided through the CRCNS program ( _CITE_ ).__label__Material|Data|Use
GANs train two deep networks in concert : a generator network that maps random noise , usually drawn from a multi - variate Gaussian , to data items ; and a discriminator network that estimates the likelihood ratio of the generator network to the data distribution , and is trained using an adversarial principle . Despite an enormous amount of recent work , GANs are notoriously fickle to train , and it has been observed [ 1 , 19 ] that they often suffer from mode collapse , in which the generator network learns how to generate samples from a few modes of the data distribution but misses many other modes , even though samples from the missing modes occur throughout the training data . To address this problem , we introduce VEEGAN , _CITE_ a variational principle for estimating implicit probability distributions that avoids mode collapse . While the generator network maps Gaussian random noise to data items , VEEGAN introduces an additional reconstructor network that maps the true data distribution to Gaussian random noise . We train the generator and reconstructor networks jointly by introducing an implicit variational principle , which encourages the reconstructor network not only to map the data distribution to a Gaussian , but also to approximately reverse the action of the generator .__label__Method|Algorithm|Produce
We used Reuters , an English - Japanese bilingual corpus , and Conversation , an English - Vietnamese corpus ( Table 4 ). These corpora were split into data sets as shown in Table 3 . Japanese sentences were analyzed by ChaSen _CITE_ , a word - segmentation tool . A number of tools were used in our experiments . Vietnamese sentences were segmented using a wordsegmentation program ( Nguyen et al ., 2003 ).__label__Method|Tool|Use
Figure 2 summarizes ROC curves of all methods averaged over 200 simulations . We see that EPIC also outperforms the competing estimators throughout all settings . To illustrate the effectiveness of the proposed EPIC method , we adopt the breast cancer data _CITE_ , which is analyzed in Hess et al . ( 2006 ). The data set contains 133 subjects with 22 , 283 gene expression levels .__label__Material|Data|Use
Python packages used for analysis include numpy ( Oliphant , 2007 ; Van der Walt , Colbert & Varoquaux , 2011 ), matplotlib ( Hunter , 2007 ), sqlalchemy ( Bayer , 2014 ), pandas ( McKinney , 2010 ), macroecotools ( Xiao et al ., 2016 ), and retriever ( Morris & White , 2013 ). R packages used for analysis include ggplot2 ( Wickham , 2009 ), magrittr ( Bache & Wickham , 2014 ), tidyr ( Wickham , 2016 ), and dplyr ( Wickham & Francois , 2016 ). All of the code and all of the publicly available data necessary to replicate these analyses is available at _CITE_ and archived on Zenodo ( Baldridge et al ., 2016 ). The CBC datasets and NABA datasets are not publicly available and therefore are not included .__label__Material|Data|Produce
There are 22 , 894 atom symmetry classes , which when paired with reaction condition yields 29 , 104 ( a , c ) tuples . Of these 29 , 104 ( a , c ) tuples , 1 , 262 have label srcreact = 1 , and 1 , 786 have label sinkreact = 1 . Atom and MO interaction data is available at our chemoinformatics portal ( _CITE_ ) under Supplements .__label__Supplement|Website|Produce
The theoretical input for each block would be 50 %. The phosphate conditions in the media are indicated on the right side ( Pi treatments ), as in panel B . Numerical values that underlie the data displayed in the panels are in _CITE_ MDS , multidimensional scaling ; Pi , phosphate ; 16S , small subunit ribosomal rRNA gene . ( TIF ) S7 Fig .__label__Material|Data|Use
are added by the organizers . License details : _CITE___label__Supplement|License|Other
We implement the credit assignment compiler in Vowpal - Wabbit ( _CITE_ ), a fast online learning library , and show that the credit assignment compiler achieves outstanding empirical performance both in accuracy and in speed for several application tasks . This provides strong simple baselines for future research and demonstrates the compiler approach to solving complex prediction problems may be of broad interest . Details experimental settings are in appendices .__label__Method|Tool|Use
Each 6 - core processor is linked to a 32 GB memory bank with independent memory controllers leading to a total system memory of 256 GB ( 32 x 8 ) that can be globally addressed from each core . The four sockets are interconnected using HyperTransport - 3 technology . Datasets A variety of datasets were chosen _CITE_ for experimentation ; these are summarized in Table 1 . We consider four datasets : ( i ) NEWS20 contains about 20 , 000 UseNet postings from 20 newsgroups . The data was gathered by Ken Lang at Carnegie Mellon University circa 1995 .__label__Material|Data|Use
Overall , SGN has contributed more than 20 , 000 manually curated gene and phenotype annotations for 14 Solanaceae species , and plans to develop PO annotations for expression data for each published Solanaceae transcriptome in the near future . The Maize Genetics and Genomics Database ( MaizeGDB ). The PO grew out of its third founding member MaizeGDB ’ s ( _CITE_ ) contribution to maize - specific controlled vocabulary ( Vincent et al . 2003 ). Currently , the maize data hosted in the PO database include genes , genetic stocks and gene models .__label__Material|Data|Introduce
A peculiar characteristic of a Twitter data are as follow : emoticons are widely used , the This work is licenced under a Creative Commons Attribution 4 . 0 International License . Page numbers and proceedings footer are added by the organizers . License details : _CITE_ org / licenses / by / 4 . 0 / maximum length of a tweet is 140 character , some words are abbreviated , or some are elongated by repeating letters of a word multiple times . The organizers of the SemEval - 2014 has provided a corpus of tweets and posted a task to automatically detect their respective sentiments .__label__Supplement|License|Other
Consequently , we set r = 10 in POS tagging . For sentiment analysis , we used all features in the source domain labeled reviews as distributional features , weighted by their scores given by Equation 4 , taking the inverse - rank . In both tasks , we parallelised similarity computations using BLAS _CITE_ level - 3 routines to speed up the computations . The source code of our implementation is publicly available . To evaluate DA for POS tagging , following Blitzer et al .__label__Method|Tool|Use
All authors contributed to discussion and revision of the final manuscript . Additional information Supplementary Information accompanies this paper at http :// www . nature . com / naturecommunications Competing financial interests : The authors declare no competing financial interests . Reprints and permission information is available online at _CITE_ How to cite this article : Herzschuh , U . et al . Glacial legacies on interglacial vegetation at the Pliocene - Pleistocene transition in NE asia . Nat .__label__Supplement|License|Other
It is important to note why the HOLI pipeline was not tested in this study . First , the HOLI pipeline as referenced by Pedersen et al . ( 2016 ) was incomplete and lacked the last common ancestor designation step as well as any user guidance or documentation in the code repository ( _CITE_ 9 March 2016 version ). Furthermore , since that time , the HOLI pipeline has continued to be developed for a new study that is not yet published ( https :// github . com / ancient - eDNA / Holi ), and it may therefore be impossible to reproduce the results of Pedersen et al . ( 2016 ) using the current repository .__label__Method|Code|Compare
Traditional QA : In this scenario answers are dynamically constructed from larger documents ( Pasca , 2001 ). We use this setup to answer questions from a biology textbook , where each section is indexed as a standalone document , and each paragraph in a given document is considered as a candidate answer . We implemented the document indexing and retrieval stage using Lucene _CITE_ . The candidate answers are scored using a linear interpolation of two cosine similarity scores : one between the entire parent document and question ( to model global context ), and a second between the answer candidate and question ( for local context ). Because the number of answer candidates is typically large ( e . g ., equal to the number of paragraphs in the textbook ), we return the N top candidates with the highest scores .__label__Method|Tool|Use
ftp . ncbi . nlm . nih . gov / blast / executables / blast +/ LATEST /) and organized in various databases by taxonomy and exchanger subtype . BLAST searches are ran on the server - side using PHP scripts and served asynchronously using Ajax ( http :// api . jquery . com / jquery . ajax /) and jQuery ( http :// jquery . com /). FASTA formatted sequences can be retrieved at the NCX - DB BLAST page by using the NCBI Entrez Programming Utilities ( _CITE_ ). Accession numbers can be entered as a comma separated list and retrieved remotely . The following parameters are implemented for BlastP searches using NCX - DB : initial word_ size match is 3 ; the minimum threshold score to add a word to the BLAST lookup table is 11 ; the compositionbased score adjustment is defined as per [ 55 ]; the heuristic value ( in bits ) for the final gapped alignment is 25 ; and the window size for multiple hits is set to 40 .__label__Method|Tool|Use
CEBS works with pathologists and ontologists on the consolidation of ontology terms . Currently , CEBS is working on a project toward linked data ( structured and computer - readable data that can be interlinked ). The diXa data infrastructure ( Ugis Sarkans , EBML - EBI ) The diXa infrastructure ( _CITE_ ) consists of a central data warehouse containing data from toxicogenomics project repositories and public databases . Apart from data from European projects , diXa also includes the public data from the National Project of Toxicogenomics in Japan , named Open TG - GATES ( Toxicogenomics ProjectGenomics Assisted Evaluation System , see below for more details ). The diXa data warehouse connects multi - omics studies , deposited in EBI resources [ ArrayExpress for transcriptomics ( http :// www . ebi . ac . uk / arrayexpress /), PRIDE for proteomics ( http :// www . ebi . ac . uk / pride / archive /), MetaboLights for metabolomics ( http :// www . ebi . ac . uk / metabolights /)] and provides a single interface for search and retrieval of “ omics ” data .__label__Material|Data|Introduce
Also , it is not surprising that haplotype frequencies estimated from the multiallelic data set are found to be less accurate than those estimated from SNPs , given the more complex nature of the data . The RCI is a relative measure , and illustrates not so much the accuracy of the algorithm , rather the effect of additional missing data . The results displayed in Tables 2 and 4 show that the algorithm handles the increase in the proportion of unknown alleles equally well for both SNPs and multiallelic data , although it should be pointed out that the RCI measure Page 9 of 13 ( page number not for citation purposes ) BMC Bioinformatics 2004 , 5 : 188 _CITE_ hˆ gives no indication of the accuracy of the point estimates , and should generally be considered in tandem with a measure such as D ( h , ). Interestingly , the results for the hˆ multiallelic data set were achieved despite departure from Hardy - Weinberg equilibrium ( HWE ) at two of the seven loci ( see Methods section ). Although this technique relies on the assumption of HWE , Niu et al .__label__Supplement|Paper|Introduce
We define a concept graph as a rooted , directed graph where the nodes represent thematic units ( called concepts ) and the edges represent relationships between concepts . Concept graphs are useful for summarizing document collections and providing a visualization of the thematic content and structure of large document sets - a task that is difficult to accomplish using only keyword search . An example of a concept graph is Wikipedia ’ s category graph _CITE_ . Figure 1 shows a small portion of the Wikipedia category graph rooted at the category MACHINE LEARNING . From the graph we can quickly infer that the collection of machine learning articles in Wikipedia focuses primarily on evolutionary algorithms and Markov models with less emphasis on other aspects of machine learning such as Bayesian networks and kernel methods .__label__Supplement|Document|Introduce
Our study demonstrates the population prevalence of clinical signs / symptoms and EBOV CT values over time in a large , diverse cohort of patients with EVD , as well as associations between symptoms / EBOV CT values and mortality . These findings have implications on surveillance , operational planning , and clinical care for future EVD outbreaks . PLOS Neglected Tropical Diseases | _CITE_ July 19 , 2017 1 / 17 Natural history of Ebola Virus Disease decision to publish , or preparation of the Author summary manuscript . Previous studies of Ebola Virus Disease ( EVD ) have focused on clinical symptoms and Competing interests : The authors have declared viral load ( or its proxy of cycle threshold value ) in the blood of patients measured the day that no competing interests exist . they begin medical care .__label__Supplement|Paper|Introduce
( 7Z ) S11 Dataset . VTK file for the distribution of actomyosin prestress colour - coded in Fig 5a . The VTK file format is described on _CITE_ ( 7Z ) S12 Dataset . VTK file for velocity shown as arrows in Fig 5a .__label__Supplement|Document|Introduce
Our algorithm differs in the use of kd - trees and in the way we handle truncation : we only assume that the variational distributions are fixed at their priors after a certain level . Experiments show that speedups relative to the standard variational algorithm can be significant . Evidenced by three recent workshops _CITE_ , nonparametric Bayesian methods are gaining popularity in the machine learning community . In each of these workshops computational efficiency was mentioned as an important direction for future research . In this paper we propose computational speedups for Dirichlet Process ( DP ) mixture models [ 1 , 2 , 3 , 4 , 5 , 6 , 7 ], with the purpose of improving their applicability in modern day data - mining problems where millions of data - cases are no exception .__label__Supplement|Paper|Extent
This section describes how this testbed has been built . The testbed must have a certain number of features which , altogether , differentiate the task from current multi - document summarization evaluations : Complex information needs . Being Information Synthesis a step which immediately follows a document retrieval process , it seems natural to start with standard IR topics as used in evaluation conferences such as TREC , CLEF or NTCIR _CITE_ . The title / description / narrative topics commonly used in such evaluation exercises are specially well suited for an Information Synthesis task : they are complex and well defined , unlike , for instance , typical web queries . We have selected the Spanish CLEF 2001 - 2003 news collection testbed ( Peters et al ., 2002 ), because Spanish is the native language of the subjects recruited for the manual generation of reports .__label__Supplement|Website|Extent
Social media and social networking sites are increasingly used by people to express their opinions , give their “ hot takes ”, on the latest breaking news , political issues , sports events , and new products . As a consequence , there has been an increasing interest on leveraging social media and social networking sites to sense and forecast opinions , as well as understand opinion dynamics . For example , political parties routinely use social media to sense people ’ s opinion about their political discourse ; quantitative investment firms measure investor sentiment and trade using social media [ 18 ]; and , corporations leverage brand sentiment , estimated from users ’ posts , likes and shares in social media and social networking sites , to design their marketing campaigns _CITE_ . In this context , multiple methods for sensing opinions , typically based on sentiment analysis [ 21 ], have been proposed in recent years . However , methods for accurately forecasting opinions are still scarce [ 7 , 8 , 19 ], despite the extensive literature on theoretical models of opinion dynamics [ 6 , 9 ].__label__Supplement|Document|Introduce
In this section , we empirically compare LLCA with the spectral clustering approach of [ 10 ] as well as with k - means clustering . For the last discretization step of LLCA ( cf . section 3 . 6 ), we use the same code contained in the implementation of the spectral clustering algorithm , available at _CITE___label__Method|Code|Use
It is basically the same as the vanilla Viterbi search often used for Japanese morphological analysis ( Kudo et al ., 2004 ), except that it runs on a consonant sequence . The key change to this Viterbi search is to make it possible to look up the dictionary directly by consonant substrings . To do this , we convert dictionary entries to possible consonant sequences referring to Microsoft IME Kana Table _CITE_ when the dictionary structure is loaded onto the memory . For example , for a dictionary entry ; KR / 7 hukubukuro , possible consonant sequences such as “ hkbkr ,” “ hukbkr ,” “ hkubkr ,” “ hukubkr ,” “ hkbukr ,”... are stored in the index structure . As for the conversion model , we employed the discriminative Kana - Kanji conversion model by Tokunaga ( 2011 ).__label__Supplement|Document|Extent
However , since the heads of nominal mentions are not trivially derivable , they are manually marked in Rich ERE . Furthermore , Light ERE lumped regions , landforms , buildings , and other structures into the Location entity type . Following ACE and to better align with TAC KBP evaluation tasks _CITE_ , Rich ERE separates the Light ERE Location entity type into Facility as well as Location types . Man - made structures and infrastructure are considered Facilities , while regions , landforms , and other non ­ descript sites fall under Locations . Examples include ( note that the heads of nominal mentions are indicated by underscoring ): In addition , we created a new class called Argument Fillers , which are entity - like participants in relations and events that are not annotated at the entity level .__label__Supplement|Website|Extent
The images or other third party material in this article are included in the article ’ s Creative Commons license , unless indicated otherwise in a credit line to the material . If material is not included in the article ’ s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use , you will need to obtain permission directly from the copyright holder . To view a copy of this license , visit _CITE_ © The Author ( s ) 2018__label__Supplement|License|Other
The task extends considerably on core entities , adding to PROTEIN four new entity types , including CHEMICAL and ORGANISM . The events extend on the GE definitions in allowing arguments of the new entity types as well as in introducing a new event category for high - level biological processes . The task was implemented in collaboration with domain experts and informed by prior studies on domain information extraction requirements ( Pyysalo et al ., 2010 ; Ananiadou et al ., 2011 ), including the support of systems such as PATRIC ( _CITE_ ).__label__Method|Tool|Extent
We see the difficulty of both data access and data sharing as an indicator of a general problem with current data sharing mechanisms : we believe that the ease of use , discoverability , availability and accessibility of data resources are crucial for promoting and facilitating data sharing for the genomics research community . The challenges of data sharing have been discussed extensively in the human genomics research community , since sharing of samples , data and results is an essential building block for progressing the body of knowledge in the field ( Callier et al ., 2014 ). Several organisations including the Research Data Alliance ( RDA ; _CITE_ ) and the Human Variome Project ( HVP ; http :// www . humanvariomeproject . org ) have made great efforts to promote capturing and sharing of research data , but hurdles in sharing genomic data still remain . In 2013 , the Global Alliance for Genomics and Health ( GA4GH ; http :// genomicsandhealth . org ) was established and has since engaged more than 180 institutions and organisations in working groups to address the challenges of regulatory restrictions , ethics , clinical demands , data representation , storage , analysis , and security related to genomic data sharing .__label__Supplement|Website|Introduce
The images or other third party material in this article are included in the article ’ s Creative Commons license , unless indicated otherwise in a credit line to the material . If material is not included in the article ’ s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use , you will need to obtain permission directly from the copyright holder . To view a copy of this license , visit _CITE_ © The Author ( s ) 2018__label__Supplement|License|Other
In this way , the input of the score function is dynamically adapted to the start - end behavior , but a classification feedback is given to each function for each decision taken . The functions of the system were actually modeled as Voted Perceptrons [ 11 ], which compute a prediction as an average of all vectors generated during training . For the batch classification setting , we modeled the functions as Voted Perceptrons and also as SVMs _CITE_ . In all cases , a function can be expressed in dual form as a combination of training instances , which allows the use of kernel functions . We work with polynomial kernels of degree 2 .__label__Method|Tool|Extent
Notably , the detected Ct values for a few selected genes were not proportionally coordinated with basemean values . One obvious outlier is MDP0000211280 , whose expression levels showed unexpected high Ct values . The higher than expected Ct values are more noticeable in PLOS ONE | _CITE_ September 21 , 2017 8 / 17 Reference genes for normalizing gene expression in apple roots the tissue types of “ 115 Rs ” and “# 75 Pu ” tissues . Both lines (# 115 and # 75 ) are known to be susceptible to these pathogens ( personal communication ). This observation may indicate its expression was suppressed in selected genotypes during pathogenesis .__label__Supplement|Paper|Introduce
[ 9 ] we used an averaged perceptron trained for 10 epochs , for all the experiments . Test - time classification : Use the classifier trained in the previous step on the Reuters test set for language Y , using the word representations WY to represent the documents . We trained the following autoencoders _CITE_ : BAE - cr which uses reconstruction error based decoder training ( see Section 2 . 1 ) and BAE - tr which uses tree - based decoder training ( see Section 2 . 2 ). Models were trained for up to 20 epochs using the same data as described earlier . BAE - cr used mini - batch ( of size 20 ) stochastic gradient descent , while BAE - tr used regular stochastic gradient .__label__Method|Algorithm|Use
We define a Twitter conversation as a chain of tweets where two users are consecutively replying to each other ’ s tweets using the Twitter reply button . We identify dyads of English - tweeting users with at least twenty conversations and collect their tweets . We use an open source tool for detecting English tweets _CITE_ , and to protect users ’ privacy , we replace Twitter userid , usernames and url in tweets with random strings . This dataset consists of 101 , 686 users , 61 , 451 dyads , 1 , 956 , 993 conversations and 17 , 178 , 638 tweets which were posted between August 2007 to July 2013 . To measure the accuracy of our model , we randomly sample 101 conversations , each with ten or fewer tweets , and ask three judges , fluent in English , to annotate each tweet with the level of self - disclosure .__label__Method|Tool|Use
We run experiments on various datasets and architectures , comparing COCOB with some popular stochastic gradient learning algorithms : AdaGrad [ Duchi et al ., 2011 ], RMSProp [ Tieleman and Hinton , 2012 ], Adadelta [ Zeiler , 2012 ], and Adam [ Kingma and Ba , 2015 ]. For all the algorithms , but COCOB , we select their learning rate as the one that gives the best training cost a posteriori using a very fine grid of values . We implemented _CITE_ COCOB ( following Algorithm 2 ) in Tensorflow [ Abadi et al ., 2015 ] and we used the implementations of the other algorithms provided by this deep learning framework . The best value of the learning rate for each algorithm and experiment is reported in the legend . We report both the training cost and the test error , but , as in previous work , e . g ., [ Kingma and Ba , 2015 ], we focus our empirical evaluation on the former .__label__Method|Code|Produce
All other aspects of GP inference remain the same . All of the experiments in this paper were performed using the standard GPML toolbox ; code to perform all experiments is available at the author ’ s website . _CITE_ Plate [ 6 ] constructs a form of additive GP , but using only the first - order and Dth order terms . This model is motivated by the desire to trade off the interpretability of first - order models , with the flexibility of full - order models . Our experiments show that often , the intermediate degrees of interaction contribute most of the variance .__label__Method|Code|Produce
We thank Kyle Grimes for editing the manuscript . We also thank The Cancer Genome Atlas network for data access ( _CITE_ ). A . I . V . acknowledges financial support from National Institutes of Health grant 7 - R01DK - 062148 - 10 - S1 ; A . I . V .__label__Supplement|Website|Other
5 . 3 ) of the persistence diagrams in combination with a linear SVM . Implementation . All experiments were implemented in PyTorch , using DIPHA _CITE_ and Perseus [ 23 ]. Source code is publicly - available at https :// github . com / c - hofer / nips2017 . We apply persistent homology combined with our proposed input layer to two different datasets of binary 2D object shapes : ( 1 ) the Animal dataset , introduced in [ 3 ] which consists of 20 different animal classes , 100 samples each ; ( 2 ) the MPEG - 7 dataset which consists of 70 classes of different object / animal contours , 20 samples each ( see [ 21 ] for more details ).__label__Method|Tool|Use
In all experiments , we use the low rank property of the sample covariance matrix and do not assume any other special structures . Our algorithm is implemented in a shared - memory architecture using OpenMP ( http :// openmp . org / wp /) and a distributed - memory architecture using OpenMPI ( http :// www . open - mpi . org ) and ScaLAPACK [ 15 ] ( http :// www . netlib . org / scalapack /). We compare CLIME - ADMM with three other methods for estimating the inverse covariance matrix , including CLIME , Tiger in package flare _CITE_ and divide and conquer QUIC ( DC - QUIC ) [ 13 ]. The comparisons are run on an Intel Zeon E5540 2 . 83GHz CPU with 32GB main memory . We test the efficiency of the above methods on both synthetic and real datasets .__label__Method|Code|Compare
To facilitate taking advantage of other genetic and epigenetic information ( such as genes , SNPs , CpG islands , DNA methylation and histone modifications ) in the relevant biological databases , it provides a directly linked server from the genomic methylation regions out to the bioinformatics secondary databases of UCSC ( 53 ), MethyCancer ( 68 ) and HHMD ( 69 ). Users may rapidly and efficiently obtain the relevant information for the genomic regions with different methylation patterns . The detailed information of identified genomic regions by the four modules of CpG_MPs from the five cell types can be downloaded from _CITE_ CpG_MPs .__label__Supplement|Document|Produce
In order to evaluate the clustering results , we use three commonly used clinical biomarkers of colon and rectal cancer ( The Cancer Genome Atlas Network , 2012 ): ( i ) micro - satellite instability ( i . e ., a hypermutable phenotype caused by the loss of DNA mismatch repair activity ) ( ii ) hypermutation ( defined as having mutations in more than or equal to 300 genes ), and ( iii ) mutation in BRAF gene . Note that these three biomarkers are not directly identifiable from the input data sources used . The preprocessed genomic characterizations of the patients can be downloaded from a public repository at _CITE_ , where DNA copy number , mRNA gene expression , DNA methylation , and mutation data consist of 20313 , 20530 , 24980 , and 14581 features , respectively . The micro - satellite instability data can be downloaded from https :// tcga - data . nci . nih . gov / tcga / dataAccessMatrix . htm . In the resulting data set , there are 204 patients with available genomic and clinical biomarker data .__label__Material|Data|Use
All models that include environmental predictors also include density dependence ( the sockeye models with environmental effects allowed density dependence to vary by population ). For each species , the best model and all models within 1 log - likelihood unit are highlighted in bold ( the best PLOS ONE | DOI : 10 . 1371 / journal . pone . 0172898 March 15 , 2017 18 / 24 Evaluating signals of EVOS , climate , and species interactions in herring and salmon populations model only being defined for this particular table — all results are included in Table 1 ). Additional details included online , _CITE_ ( DOCX ) S4 Table . Detailed results for models that only include effects of juvenile competition .__label__Supplement|Document|Produce
KO mice could not be generated for three genes , as heterozygous Pstk mice were infertile and , confirming published observations , KO of Cask49 and Dll450 resulted in heterozygous lethality . Lexicon ’ s KO strategies for Agpat2 , Clcn7 , Cldn18 , Fam20c , Gnptab , Lrp5 , Lrrk1 , Sgpl1 , Stk36 , Tph1 , Tph2 and Wnt16 are provided in the publications of these phenotypes . KO strategies used to generate 4077 of Lexicon ’ s KO mouse lines are provided at the Taconic Farms website ( _CITE_ ). Supplementary Table S1 summarizes KO strategies for all 93 genes discussed in this review . A total of 139 X - linked genes were KO ’ d , with bone data for 133 KOs reported .__label__Supplement|Website|Use
The goal of this task is to classify reviews for cellphones as positive or negative . 5 , 741 sentences were collected from an Web - BBS discussion about cellphones in which users were directed to submit positive reviews separately from negative reviews . Each sentence is represented in a word - based dependency tree using a Japanese dependency parser CaboCha _CITE_ . The task is to classify chemical compounds by carcinogenicity . We used the PTC data sets consisting of 417 compounds with 4 types of test animals : male mouse ( MM ), female mouse ( FM ), male rat ( MR ) and female rat ( FR ).__label__Method|Tool|Use
CROSS is freely available at _CITE_ new submission / cross .__label__Method|Tool|Produce
Unstructured Information Management Architecture ( UIMA ) ( Ferrucci and Lally , 2004 ) is a framework that supports the interoperability of mediaprocessing software components by defining common data structures and interfaces the components exchange and implement . The architecture has been gaining interest from academia and industry alike for the past decade , which resulted in a multitude of UIMA - supporting repositories of analytics . Notable examples include METANET4U components ( Thompson et al ., 2011 ) featured in U - Compare _CITE_ , DKPro ( Gurevych et al ., 2007 ), cTAKES ( Savova et al ., 2010 ), BioNLP - UIMA Component Repository ( Baumgartner et al ., 2008 ), and JULIE Lab ’ s UIMA Component Repository ( JCoRe ) ( Hahn et al ., 2008 ). However , despite conforming to the UIMA standard , each repository of analytics usually comes with its own set of type systems , i . e ., representations of data models that are meant to be shared between analytics and thus ensuring their interoperability . At present , UIMA does not facilitate the alignment of ( all or selected ) types between type systems , which makes it impossible to combine analytics coming from different repositories without an additional programming effort .__label__Method|Algorithm|Compare
Additional information Supplementary Information accompanies this paper at https :// doi . org / 10 . 1038 / s41467017 - 02374 - 7 . Competing interests : The authors declare that they have no competing financial interests . Reprints and permission information is available online at _CITE_ Publisher ' s note : Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations . Open Access This article is licensed under a Creative Commons Attribution 4 . 0 International License , which permits use , sharing , adaptation , distribution and reproduction in any medium or format , as long as you give appropriate credit to the original author ( s ) and the source , provide a link to the Creative Commons license , and indicate if changes were made . The images or other third party material in this article are included in the article ’ s Creative Commons license , unless indicated otherwise in a credit line to the material .__label__Supplement|License|Other
Thus , the expected output was the syntactic aspect of subcategorization frames of verbs . We worked with the verbal sense as the unit . We compared the patterns associated to each verbal sense by IRASubcat with the subcategorization frames manually associated to the verbs at the a lexical data base of SenSem verbs _CITE_ . We manually inspected the results for the 20 most frequent verbal senses . Results can be seen at Table 1 .__label__Material|Data|Compare
lumbar lordosis ( 20 ° to 70 °) computed via X - ray [ 51 ]. As we measured the sagittal profiles of spinous processes labelled by skin markers , we decided to consider as reference values the mean profile values calculated from our sample population . Specifically , we defined kyphosis PLOS ONE | _CITE_ June22 , 2017 12 / 31 Normative 3D posture and spine data in healthy young adults and lordosis as backward - and forward - facing convex curves ( with related angle values ) without considering their specific location along the spine . When statistically significant changes approached this mean value , it was classified as an Improvement .__label__Supplement|Paper|Extent
To demonstrate the effectiveness of our split - merge moves , we compare three algorithms : batch variational inference ( bHDP ), online variational inference without split - merge ( oHDP ), and online variational inference with split - merge ( oHDP - SM ). On the NIPS corpus we also compare these three methods to collapsed Gibbs sampling ( CGS ) and the CRF - style oHDP model ( oHDP - CRF ) proposed by [ 4 ]. _CITE_ We test the models on one synthetic and two real datasets : Bars A 20 - topic bars dataset of the type introduced in [ 18 ], where topics can be viewed as bars on a 10 x 10 grid . The vocabulary size is 100 , with a training set of 2000 documents and a test set of 200 documents , 250 words per document . NIPS 1 , 740 documents from the Neural Information Processing Systems conference proceedings , 1988 - 2000 .__label__Method|Algorithm|Compare
In the third experiment we demonstrate the ability of our method to infer the spectrum of airline passenger data , to perform long - range extrapolations on real data , and to demonstrate the utility of accounting for uncertainty in the kernel . In the final experiment we demonstrate the scalability of our method through training the model on a 100 , 000 data point sound waveform . Code is available at _CITE_ f ( X )__label__Method|Code|Produce
The starting point of the work reported here is Walenty , a valence dictionary for Polish described in Przepiórkowski et al . 2014 and available from _CITE_ ( see § 1 . 1 ). Walenty contains some valence schemata for verbal idioms ; e . g ., one of the schemata for xuc ‘ forge ’ says that it combines with a nominal subject , a nominal object and a prepositional phrase consisting of the preposition NA ` on ' and the accusative singular form of the noun PAMi � c ‘ memory ’ – this represents the idiom ktos kuje cos na pamigc ‘ somebody rote learns something ’, lit . ‘ somebody forges something onto memory ’.__label__Material|Data|Extent
We manually checked all the cases of majority agreement , correcting only 7 . 92 % of the majority adjudications , and manually adjudicated all the snippets for which there was no agreement . We observed during adjudication that in many cases the disagreement was due to the existence of subtle sense distinctions , like between MORTAL KOMBAT ( VIDEO GAME ) and MORTAL KOMBAT ( 2011 VIDEO GAME ), or between THE DA VINCI CODE and INACCURACIES IN THE DA VINCI CODE . The average number of senses associated with the search results of each query was 7 . 69 ( higher than in previous datasets , such as AMBIENT + MORESQUE _CITE_ , which associates 5 . 07 senses per query on average ). Following Di Marco and Navigli ( 2013 ), we evaluated the systems ’ outputs in terms of the snippet clustering quality ( Section 3 . 1 ) and the snippet diversification quality ( Section 3 . 2 ). Given a query q ∈ Q and the corresponding set of 64 snippet results , let C be the clustering output by a given system and let G be the gold - standard clustering for those results .__label__Material|Data|Compare
In this section , we empirically compare our algorithms with the existing algorithms in terms of clustering performance and computational time ( on a single desktop ). For NSN , we used the fast implementation described in Section A . 1 . The compared algorithms are K - means , K - flats , SSC , LRR , SCC , TSC _CITE_ , and SSC - OMP . The numbers of replicates in K - means , K - flats , and the K means used in the spectral clustering are all fixed to 10 . The algorithms are compared in terms of Clustering error ( CE ) and Neighborhood selection error ( NSE ), defined as where ⇧ L is the permutation space of [ L ].__label__Method|Algorithm|Compare
In our implementation , we first solve ( 14 ) with standard relaxation ( W is the identity ) and then with reweighted -` 1 . To handle large motion , we use a pyramid with scale factor 0 . 5 and up to 4 levels ; λ and µ are fixed at 0 . 002 and 0 . 001 ( Flower Garden ) and 0 . 0006 and 0 . 0003 ( Middlebury ) respectively . To make comparison with [ 29 ] fair , we modify the code provided online _CITE_ to include anisotropic regularization ( Fig . 1 ). Note that no occlusion is present in the residual of the motion field computed by TV - L1 , and subsequently the motion estimates are less precise around occluding boundaries ( top - left corner of the Flower Garden , plane in the left in Venus ).__label__Method|Code|Extent
OCP provides Web - services for individual tile requests that extract image planes from volume databases . To accelerate visualization when accessing nearby slices or when viewing data repeatedly , OCP manages a hierarchy of caches . First , an in - memory tile cache is maintained in the OCP data cluster using memcached ( _CITE_ ). The cache contains the most frequently accessed tiles , subject to the cluster ’ s memory capacity . Tile requests that miss the memory cache are rendered on demand by the Web server .__label__Method|Tool|Use
This is particularly true with respect to Indian languages . In the last 15 years or so , MT into Indian languages ( especially Hindi ) has gained tremendous research interest in India and elsewhere . Many English to Hindi and Indian Languages to Indian Languages MT systems have been designed , for example AnglaBharati ( Sinha et al ., 1995 ), Anusaaraka ( Chaudhury et al ., 2010 ), Anuvadaksh , Google , Sampark , MaTra _CITE_ ( Ananthakrishnan et al ., 2006 ), to name just a few . However , the issue of evaluating the output of these MT systems has remained rather unexplored . The state - of - the - art methods for automatic MT evaluation are represented by BLEU ( Papineni et al ., 2002 ) and closely related NIST ( Doddington , 2002 ), METEOR ( Banerjee and Lavie , 2005 ; Lavie and Agarwal , 2007 ) and TER ( Snover et al ., 2006 ).__label__Method|Tool|Introduce
The Gaussian prior was set to 0 . 1 , and the maximum training iterations to 100 . In order to assess the performance of the final system , MAXENT was compared with support vector machines ( SVM ) using the SVMl ' ght toolkit ( Joachims , 1999 ). Since both the classifiers assign a confidence to each prediction , a varying threshold can be applied to the output of the classifier to provide a precision - recall 2_CITE_ tradeoff . Candidate relations were generated by considering entity pairs of the appropriate type , taking into account the distance between the entities . It was thought that inter - sentential and intra - sentential relations would require different feature sets and different models , so inter - and intra - sentential candidates were generated separately .__label__Method|Tool|Compare
In the preliminary experiment , 27 , 239 Thai utterances with a mix of sentences and phrases from a general domain corpus are tested . The input was word - segmented by JwordSeg ( _CITE_ ) and approved by linguists . In the test corpus , the longest utterance contains seventeen words , and the shortest utterance contains two words .__label__Method|Tool|Use
We train an SVM classifier on the training set , using the sentence vectors composed by a model as features , and report accuracy on the test set . State of the art is obtained by Le and Mikolov ( 2014 ) with the Paragraph Vector approach we describe below . The source corpus we use to build the lexical vectors is created by concatenating three sources : ukWaC , a mid - 2009 dump of the English Wikipedia _CITE_ and the British National Corpus ( about 2 . 8B words in total ). We build vectors for the 180K words occurring at least 100 times in the corpus . Since our training procedure requires parsed trees , we parse the corpus using the Stanford parser ( Klein and Manning , 2003 ).__label__Material|Data|Extent
( 2002 ), who define MWEs as : different but related phenomena [ which ] can be described as a sequence of words that acts as a single unit at some level of linguistic analysis . This generic and intentionally vague definition can be narrowed down according to the application needs . For example , for the statistical machine translation ( MT ) system _CITE_ used in the examples shown in Table 1 , an MWE is any sequence of words which , when not translated as a unit , generates errors : ungrammatical or unnatural verbal constructions ( sentence 1 ), awkward literal translations of idioms ( sentence 2 ) and problems of lexical choice and word order in specialised texts ( sentence 3 ). These examples illustrate the importance of correctly dealing with MWEs in MT applications and , more generally , MWEs can speed up and help remove ambiguities in many current NLP applications , for example : Despite the importance of MWEs in several applications , they are often neglected in the design and construction of real - life systems . In 1993 , Smadja pointed out that “... although disambiguation was originally considered as a performance task , the collocations retrieved have not been used for any specific computational task .” Most of the recent and current research in the MWE community still focuses on MWE acquisition instead of integration of automatically acquired or manually compiled resources into applications .__label__Method|Tool|Introduce
Provenance and peer review Not commissioned ; peer reviewed for ethical and funding approval prior to submission . Open Access This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial ( CC BY - NC 4 . 0 ) license , which permits others to distribute , remix , adapt , build upon this work noncommercially , and license their derivative works on different terms , provided the original work is properly cited and the use is non - commercial . See : _CITE___label__Supplement|License|Other
For example , functionality specification before implementation was described for CGAL and is typical of large projects but would have been cumbersome for Moses . Secondly , the aims of Moses and these projects are different . The goal of the CGAL project is to ‘ make ... computational geometry available for industrial application ’ _CITE_ . Both CGAL and DCMTK are used extensively in commercial applications . Therefore , issues such robustness , cross - platform compatibility and easeof - use are predominant for these projects .__label__Supplement|Document|Introduce
For example , the CUI for “ Original ,” another term mapped from the caption shown in Figure 1 , is “ C0205313 .” Our results indicate that “ C0205313 ,” which occurs 19 times in our evaluation data , never identifies a useful indexing term . F . 2 Semantic Type ( nominal ): The concept ’ s semantic categorization . There are currently 132 different semantic types _CITE_ in the UMLS Metathesaurus . For example , The semantic type of “ Original ” is “ Idea or Concept .” F . 3 Presence in Caption ( nominal ): true if the phrase that generated the concept is located in the image caption ; false if the phrase is located in the image mention . F . 4 MeSH Ratio ( real ): The ratio of words ci in the concept c that are also contained in the Medical Subject Headings ( MeSH terms ) M assigned to the document to the total number of words in the concept .__label__Material|Data|Introduce
The main reference model of the painting ontology is the OWL 2 imple mentation of the CRM . The additional models that are correctly integrated in the ontology are : SOCH , Time Ontology , SUMO and Mid - LevelOntology . _CITE_ The painting ontology was constructed manually using the Prot ´ eg ´ e editing tool . Integration of the ontology concepts are accomplished by using the OWL construct : intersectionOf as specified below : The schemata that are stated in the above example are denoted with the following prefixes : painting ontology (& painting ), SOCH (& ksamsok ), Mid - Level - Ontology (& milo ) and CIDOCCRM ontology (& core ). In this example , the class Painting is defined in the painting ontology as a subclass of E22 Man - Made Object class from the CIDOC - CRM ontology and is an intersection of two classes , i . e .__label__Method|Algorithm|Introduce
The electrode array was self - made : glass - coated platinum wires ( Thomas Recording , Germany ) were sharpened ( outer diameter : 80 µm , platinum diameter : 25 µm , impedance was about 500 kO ), and 5 of them were arranged parallel to each other . The distance between the tips was 250 µm . To verify that action potentials propagate through the middle part of the corpus callosum used for subsequent counting of cells , we exposed the surface of the cortex contralateral to the implanted PLOS Biology | _CITE_ August22 , 2017 23 / 32 Neuronal activity and oligodendrocyte precursor cells electrode array and attached the recoding ball electrode to it . We then applied low frequency stimulation to the array and tested whether we were able to record field potentials at the contralateral side . This was possible in each mouse .__label__Supplement|Paper|Compare
We thank Alexander Ecker and the lab of Andreas Tolias for sharing their data with us [ 5 ] ( see _CITE_ ), and for allowing us to use it in this publication , as well as Maneesh Sahani and Alexander Ecker for valuable comments . This work was funded by the Gatsby Charitable Foundation ( MP and GB ) and the German Federal Ministry of Education and Research ( MP and JHM ) through BMBF ; FKZ : 01GQ1002 ( Bernstein Center T ¨ ubingen ). Code available athttp :// www . mackelab . org / code .__label__Material|Data|Use
In this section we present experimental results on several multi - class problems : segment , satimage , and letter from the Statlog collection [ 9 ], USPS [ 4 ], and MNIST [ 7 ]. All data sets are available at _CITE_ t . Their numbers of classes are 7 , 6 , 26 , 10 , and 10 , respectively . From thousands of instances in each data , we select 300 and 500 as our training and testing sets . We consider support vector machines ( SVM ) with RBF kernel e − xi − xj  2 as the binary classifier .__label__Material|Data|Use
Given that a prior model must be assumed to achieve satisfactory error estimation , an obvious course of action is to derive an optimal classifier based © 2014 Knight et al . ; licensee BioMed Central Ltd . This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( _CITE_ ), which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly credited . The Creative Commons Public Domain Dedication waiver ( http :// creativecommons . org / publicdomain / zero / 1 . 0 /) applies to the data made available in this article , unless otherwise stated .__label__Supplement|License|Other
The images or other third party material in this article are included in the article ’ s Creative Commons license , unless indicated otherwise in a credit line to the material . If material is not included in the article ’ s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use , you will need to obtain permission directly from the copyright holder . To view a copy of this license , visit _CITE_ © The Author ( s ) 2018__label__Supplement|License|Other
An implementation of semi - CRFs is available at _CITE_ , and a NER package using this package is available on http :// minorthird . sourceforge . net .__label__Method|Code|Use
When assessing the performance on each of the tasks , we notice that the advantage of learning jointly is particularly significant for those tasks with smaller number of observations . News Ontologies In this experiment , we consider multiclass learning in a 2 - task problem . We use the Reuters1 - v2 news article dataset [ 18 ] which has been pre - processed _CITE_ . In the pre - processing stage , the label hierarchy is reorganized by mapping the data set to the second level of topic hierarchy . The documents that only have labels of the third or fourth levels are mapped to their parent category of the second level .__label__Material|Data|Use
We have used data collected from high - throughput phenotyping , which is based on a pipeline concept where a mouse is characterized by a series of standardized and validated tests underpinned by standard operating procedures ( SOPs ). The phenotyping tests chosen cover a variety of disease - related and biological systems , including the metabolic , cardiovascular , bone , neurological and behavioural , sensory and haematological systems and clinical chemistry . The IMPRESS database ( _CITE_ ), defines all screens , the purpose of the screen , the experimental design , detailed procedural information , the data that is to be collected , age of the mice , significant metadata parameters , and data quality control ( QC ). Experimental design . At each institute , phenotyping data from both sexes is collected at regular intervals on age - matched wildtype mice of equivalent genetic backgrounds .__label__Material|Data|Introduce
Unfortunately , their method requires lengthy guidelines and substantial annotator training effort , which are time consuming and costly . Thus , a simple , robust and replicable evaluation method is needed . Recently , crowdsourcing services such as Amazon Mechanical Turk ( AMT ) and CrowdFlower ( CF ) _CITE_ have been employed for semantic inference annotation ( Snow et al ., 2008 ; Wang and CallisonBurch , 2010 ; Mehdad et al ., 2010 ; Negri et al ., 2011 ). These works focused on generating and annotating RTE text - hypothesis pairs , but did not address annotation and evaluation of inference rules . In this paper , we propose a novel instance - based evaluation framework for inference rules that takes advantage of crowdsourcing .__label__Supplement|Website|Introduce
Raw and converted data are deposed to MassIVE ( MSV000079811 ) and ProteomeXchange ( PXD004308 ). Source code of Diffacto is freely available at _CITE_ under Apache 2 . 0 license .__label__Method|Code|Produce
Second , we compared the performance of GP - Vol against standard econometric models GARCH , EGARCH and GJRGARCH on fifty real financial time series . Finally , we compared RAPCF with the batch MCMC method PGAS in terms of accuracy and execution time . The code for RAPCF in GP - Vol is publicly available at _CITE___label__Method|Code|Produce
Raw sequence data are available under GEO series accession numbers GSE86337 ( pilot experiment ) and GSE64098 ( mixture experiment ). Analysis scripts and processed data are available from the Supplementary Information website at _CITE___label__Supplement|Website|Produce
Although previous systematic reviews have assessed individual outcomes [ 8 – 12 , 101 , 105 – 109 ], we have found no other published reviews synthesizing the evidence for all long - term risks and benefits of cesarean delivery relating to mother , baby , and subsequent pregnancies . There is a lack of documented evidence about medium - to long - term outcomes in women and their babies after a planned cesarean delivery or a planned vaginal birth [ 4 ]. Therefore , the findings of this review will form a valuable and necessary addition to discussions about mode PLOS Medicine | _CITE_ January23 , 2018 12 / 22 Meta - analysis of the long - term risks and benefits of cesarean delivery of delivery and consenting for planned cesarean delivery . Patients may attribute different weight to the outcomes ; for example , some might prioritize minimizing the risk of stillbirth in a future pregnancy , while others might prioritize minimizing the risk of respiratory morbidity for their baby . The information included in this review will allow women ( and their caregivers ) to make more personally relevant decisions .__label__Supplement|Paper|Extent
We empirically analyzed the accuracy of the algorithms proposed here against each other and against the available implementations of TWILP ( _CITE_ ) and K & P ( http :// www . cs . helsinki . fi / u / jazkorho / aistats - 2013 /) on a collection of data sets from the UCI repository . The S + K & P and S2 algorithms were implemented ( purely ) in Matlab . The data sets were selected so as to span a wide range of dimensionality , and were preprocessed to have variables discretized over the median value when needed .__label__Method|Code|Compare
Strictly speaking , this means that almost all these studies focused on the effects of heavy – AD on © The Author ( s ). 2017 Open Access This article is distributed under the terms of the Creative Commons Attribution 4 . 0 International License ( http :// creativecommons . org / licenses / by / 4 . 0 /), which permits unrestricted use , distribution , and reproduction in any medium , provided you give appropriate credit to the original author ( s ) and the source , provide a link to the Creative Commons license , and indicate if changes were made . The Creative Commons Public Domain Dedication waiver ( _CITE_ ) applies to the data made available in this article , unless otherwise stated . Kurai et al . Genes and Environment ( 2017 ) 39 : 25 Page 2 of 8 health .__label__Supplement|License|Other
System administrators from the Texas Advanced Computing Center ( TACC ) at The University of Texas at Austin made configuration changes on our request . This work made use of the resources provided by the Edinburgh Compute and Data Facility ( http :// www . ecdf . ed . ac . uk /). The ECDF is partially supported by the eDIKT initiative ( _CITE_ ). The research leading to these results has received funding from the European Union Seventh Framework Programme ( FP7 / 2007 - 2013 ) under grant agreement 287658 ( EU BRIDGE ).__label__Supplement|License|Other
Directional information ( up - or downregulation ) for each gene also was incorporated in the analysis to assess the similarities between datasets . To enable comparison across different arrays , orthologs were identified for each pair of organisms [ 99 ]. Ortholog identification was based on information obtained from Mouse Genome Informatics ( MGI ) at Jackson Lab ( _CITE_ ), HomoloGene at NCBI ( http :// www . ncbi . nlm . nih . gov ), and Ensembl ( http :// www . ensembl . org ). The gene overlap P - value calculated by NextBio indicates a statistically significant association between two given gene sets . The detailed methods for comparison of data sets are given in Additional file 8 .__label__Supplement|Website|Extent
For study # 1 , our base system ( Spitkovsky et al ., 2010b ) is an instance of the popular ( unlexicalized ) Dependency Model with Valence ( Klein and Manning , 2004 ). This model was trained using hard EM on WSJ45 ( WSJ sentences up to length 45 ) until successive changes in per - token cross - entropy fell below 2 − 20 bits ( Spitkovsky et al ., 2010b ; 2010a , § 4 ). _CITE_ We confirmed that the base model had indeed converged , by running 10 steps of hard EM on WSJ45 and verifying that its objective did not change much . Next , we applied a single alternation of simple lateen EM : first running soft EM ( this took 101 steps , using the same termination criterion ), followed by hard EM ( again to convergence — another 23 iterations ). The result was a decrease in hard EM ’ s cross - entropy , from 3 . 69 to 3 . 59 bits per token ( bpt ), accompanied by a 2 . 4 % jump in accuracy , from 50 . 4 to 52 . 8 %, on Section 23 of WSJ ( see Table 1 ).__label__Method|Algorithm|Introduce
The Web - based interface allows the use of the translation system to any computer connected to the Internet . Given a string f in the source language , the goal of the statistical machine translation is to select the string e in the target language which maximizes the posterior distribution Pr ( e | f ). By introducing the hidden word alignment variable a , the following approximate optimization criterion can be applied for that purpose : At this time , Statistical Machine Translation ( SMT ) has empirically proven to be the most competitive approach in international competitions like the NIST Evaluation Campaigns and the International Workshops on Spoken Language Translation ( IWSLT - 2004 _CITE_ and IWSLT - 2005 ). In this paper we describe our multi - lingual phrase - based Statistical Machine Translation system which can be accessed by means of a Web page . Section 2 presents the general log - linear framework to SMT and gives an overview of our phrase - based SMT system .__label__Supplement|Website|Introduce
Our GLM graphical models will be important for understanding genomic networks learned from other high - throughput technologies that do not produce approximately Gaussian data . Here , we demonstrate the versatility of our model by learning two cancer genomic networks , a genomic copy number aberration network ( from aCGH data ) for Glioblastoma learned by multinomial graphical models and a meta - miRNA inhibitory network ( from next generation sequencing data ) for breast cancer learned by Poisson graphical models . Level III data , breast cancer miRNA expression ( next generation sequencing ) [ 13 ] and copy number variation ( aCGH ) Glioblastoma data [ 14 ], was obtained from the the Cancer Genome Atlas ( TCGA ) data portal ( _CITE_ ), and processed according to standard techniques . Data descriptions and processing details are given in the supplemental materials . A Poisson graphical model and a multinomial graphical model were fit to the processed miRNA data and aberration data respectively by performing neighborhood selection with the sparsity of the graph determined by stability selection [ 15 ].__label__Material|Data|Use
Another aspect we would like to distinguish is whether an instance of a pattern is a simile or not . We plan to tackle this using machine learning . Semantic features from an ontology like the one used in PDEV _CITE_ , or a more comprehensive work such as WordNet , can carry the information whether T and V belong to similar semantic categories . We expect other information , such as distributional and distributed word vector representations , to be of use . It may also be of interest to decide whether an instance is conventional or creative .__label__Method|Algorithm|Extent
